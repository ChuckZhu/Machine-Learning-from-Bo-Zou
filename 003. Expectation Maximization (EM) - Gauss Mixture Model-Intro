''' 
    EM Algorithm is an unsupervised learning method
    Gauss Mixture Model is a practical part of EM Algorithm
    We can solve clustring analysis, machine learning visualization and more problems
    Gauss Mixture is a combination of Gauss distribution (Normal disctribution) and Bayesian theorem
    For concave function we need to use Jensen's Inequality 
    From E-step we get probability of one varaible came from one group Q
    From M-strp we get maximum likelihood estimator(MLE) Î¸ from mixture model
    Until it convergence
'''
def calcEM(height):
    N = len(height)
    gp = 0.5   #Girl probability
    bp = 0.5   #Boy probability
    # Prior: Minimum and Maximum
    gmu,gsigma = min(height),1 
    bmu,bsigma = max(height),1
    ggamma = range(N)
    bgamma = range(N)
    cur = [gp, bp, gmu, gsima, bmu, bsigma]
    now = []
    
    times = 0
    while times < 100:
        i = 0
        for x in height:
            ggamma[i] = gp * gauss(x, gmu, gsigma)
            bgamma[i] = bp * gauss(x, bmu, bsigma)
            s = ggamma[i] + bgamma[i]
            ggamma[i] /= s
            bgamma[i] /= s
            i += 1
            
            gn = sum(ggamma)
            gp = float(gn) / float(N)
            bn = sum(bgamma)
            bp = float(bn) / float(N)
            gmu = averageWeight(height, ggamma, gn)
            gsima = varianceWeight(height, ggamma, gmu, gn)
            bmu = averageWeight(height, bgamma, bn)
            bsigma = varianceWeight(height, bgamma, bmu, bn)
            
            now = [gp, bp, gmu, gsigma, bmu, bsigma]
            if isSame(cur, now):
                break
            cur = now
            print "Time:\t", times
            print "Girl mean/gsigma:\t", gmu,gsigma
            print "Boy mean/bsigma:\t", bmu,bsigma
            print "Boy/Girl:\t", bn, gn, bn+gn
            print "\n\n"
            times += 1
            return now
